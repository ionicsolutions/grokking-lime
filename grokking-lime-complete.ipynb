{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grokking LIME: How can we explain why an image classifier \"knows\" whatâ€™s in a photo without looking inside the model?\n",
    "\n",
    "Kilian Kluge, [Inlinity](https://www.inlinity.ai) & [XAI Studio](https://www.xai-studio.de)\n",
    "\n",
    "[https://github.com/ionicsolutions/grokking-lime](https://github.com/ionicsolutions/grokking-lime)\n",
    "\n",
    "\n",
    "- GitHub: [ionicsolutions](https://github.com/ionicsolutions)\n",
    "- Twitter: [@kilian_kluge](https://www.twitter.com/kilian_kluge)\n",
    "\n",
    "<div style=\"width: 100%; margin-bottom: 100px;\">\n",
    "    <div><a href=\"https://www.inlinity.ai\"><img src=\"assets/inlinity_logo_electric_blue.png\" style=\"height:60px; margin-bottom: 30px;\" /></a></div><div>\n",
    "    <a href=\"https://www.xai-studio.de\"><img src=\"assets/xai-studio-logo-m.png\" style=\"height:60px;\" /></a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable AI? XAI? Interpretable Machine Learning?\n",
    "\n",
    "<img src=\"assets/opaque_interpretable.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/explainable.png\" width=\"500\" />\n",
    "<div style=\"height: 230px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIST's Four Principles of XAI\n",
    "![NIST's Four Principles of XAI](assets/four_principles.png)\n",
    "<div style=\"height: 200px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization aids\n",
    "\n",
    "import pandas as pd\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "def show_image(array: np.ndarray) -> Image:\n",
    "    return Image.fromarray(np.uint8(array))\n",
    "\n",
    "def show_segments(image: np.ndarray, segment_mask: np.ndarray) -> Image:\n",
    "    return show_image(255 * mark_boundaries(image, segment_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 200px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image = Image.open(\"camera.png\")\n",
    "full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(full_image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[15,77,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 200px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import (\n",
    "    MobileNetV2, preprocess_input, decode_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = model.predict(preprocess_input(image[None,:,:,:]))\n",
    "model_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/opaque.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME: Local Interpretable Model-Agnostic Explanations\n",
    "\n",
    "Ribeiro et al. (2016): [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\n",
    "\n",
    "\n",
    "1. [Segment the image](#Step-1:-Segment-the-image)\n",
    "2. [Generate samples](#Step-2:-Generate-samples)\n",
    "3. [Generate images](#Step-3:-Generate-images)\n",
    "4. [Predict images](#Step-4:-Predict-images)\n",
    "5. [Fit linear model](#Step-5:-Fit-linear-model)\n",
    "6. [Generate visual explanation](#Step-6:-Generate-visual-explanation)\n",
    "\n",
    "<div style=\"height: 200px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Segment the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import felzenszwalb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "segment_mask = felzenszwalb(image, scale=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "show_segments(image, segment_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "segment_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "segment_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of segments:\", np.max(segment_mask) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(segment_mask: np.ndarray, num_of_samples: int) -> np.ndarray:\n",
    "    ## live-code\n",
    "    num_of_segments = np.max(segment_mask) + 1\n",
    "\n",
    "    samples = np.random.rand(num_of_samples, num_of_segments) > 0.4\n",
    "    \n",
    "    ## /live-code\n",
    "    return samples.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_samples(segment_mask, 128)\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "pd.DataFrame(samples).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(image: np.ndarray,\n",
    "                    segment_mask: np.ndarray,\n",
    "                    samples: np.ndarray) -> np.ndarray:\n",
    "    ## live-code\n",
    "    images = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        \n",
    "        mask = np.zeros(shape=segment_mask.shape, dtype=int)\n",
    "        \n",
    "        for segment_id in np.unique(segment_mask):\n",
    "            \n",
    "            if sample[segment_id] == 1:\n",
    "                \n",
    "                mask[segment_mask == segment_id] = 1\n",
    "        \n",
    "        images.append(mask[:, :, None] * image)\n",
    "        \n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generate_images(image, segment_mask, samples)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "show_image(images[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "predictions = model.predict(preprocess_input(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "linear_model = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(samples).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m distances \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(samples, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "distances = np.linalg.norm(samples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## live-code\n",
    "linear_model.fit(samples, predictions[:, 759], sample_weight=distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.coef_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate visual explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualime.explain import render_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_explanation(image,\n",
    "                   segment_mask,\n",
    "                   linear_model.coef_,\n",
    "                   positive=\"green\",\n",
    "                   negative=\"violet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links & further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This talk/notebook:\n",
    "  - [github.com/ionicsolutions/grokking-lime](https://github.com/ionicsolutions/grokking-lime)\n",
    "- Papers:\n",
    "  - Phillips et al. (2021): [Four Principles of Explainable AI](https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8312.pdf) (NIST)\n",
    "  - Ribeiro et al. (2016): [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\n",
    "- LIME implementations:\n",
    "  - [Original LIME on GitHub](https://github.com/marcotcr/lime) & [on PyPI](https://pypi.org/project/lime/)\n",
    "  - [VisuaLIME on GitHub](https://github.com/xai-demonstrator/visualime) & [on PyPI](https://pypi.org/project/visualime/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}